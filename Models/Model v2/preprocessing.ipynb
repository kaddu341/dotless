{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import * #suprisingly the only import needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary of arabic letters from dotted to dotless. (credit: @kaddu341)\n",
    "letter_dict = {\n",
    "    \"ا\": \"ا\",\n",
    "    \"أ\": \"ا\",\n",
    "    \"إ\": \"ا\",\n",
    "    \"آ\": \"ا\",\n",
    "    \"ب\": \"ب\",\n",
    "    \"ت\": \"ب\",\n",
    "    \"ث\": \"ب\",\n",
    "    \"ج\": \"ح\",\n",
    "    \"ح\": \"ح\",\n",
    "    \"خ\": \"ح\",\n",
    "    \"د\": \"د\",\n",
    "    \"ذ\": \"د\",\n",
    "    \"ر\": \"ر\",\n",
    "    \"ز\": \"ر\",\n",
    "    \"س\": \"س\",\n",
    "    \"ش\": \"س\",\n",
    "    \"ص\": \"ص\",\n",
    "    \"ض\": \"ص\",\n",
    "    \"ط\": \"ط\",\n",
    "    \"ظ\": \"ط\",\n",
    "    \"ع\": \"ع\",\n",
    "    \"غ\": \"ع\",\n",
    "    \"ف\": \"ف\",\n",
    "    \"ق\": \"ف\",\n",
    "    \"ك\": \"ك\",\n",
    "    \"ل\": \"ل\",\n",
    "    \"م\": \"م\",\n",
    "    \"ن\": \"ن\",\n",
    "    \"و\": \"و\",\n",
    "    \"ؤ\": \"و\",\n",
    "    \"ه\": \"ه\",\n",
    "    \"ة\": \"ه\",\n",
    "    \"ي\": \"ى\",\n",
    "    \"ى\": \"ى\",\n",
    "    \"ئ\": \"ى\",\n",
    "    \" \": \" \",\n",
    "}\n",
    "letter_set = set(letter_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces multiple spaces, or whatever char designated by the perameter into one char. (helper function)\n",
    "def replace(string, char):\n",
    "    while char+char in string:\n",
    "        string = string.replace(char+char, char)\n",
    "\n",
    "    return string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential function, parses arabic dotted text into dotless text. \n",
    "# Returns a dict with keys \"clean\" and \"dotless\". \n",
    "# This format is required for the datasets.map() function.\n",
    "\n",
    "#unused, see below functions, also this is not batched\n",
    "def parse_text(text):\n",
    "    \n",
    "  text = text[\"text\"].strip(\" \")\n",
    "  \n",
    "  clean_chars = [char for char in text if char in letter_set]\n",
    "  clean_string = ''.join(clean_chars)\n",
    "\n",
    "  dotless_chars = [letter_dict[char] for char in clean_chars]\n",
    "  dotless_string = ''.join(dotless_chars)\n",
    "      \n",
    "  clean_string = replace(clean_string, ' ')\n",
    "  dotless_string = replace(dotless_string, '_')\n",
    "  \n",
    "  return {\"clean\": clean_string, \"dotless\": dotless_string}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_clean_text(example):\n",
    "  \n",
    "  clean = []\n",
    "  \n",
    "  for text in example[\"text\"]:\n",
    "    text = text.strip(\" \")\n",
    "    \n",
    "    clean_chars = [char for char in text if char in letter_set]\n",
    "    clean_string = ''.join(clean_chars)\n",
    "    \n",
    "    clean_string = replace(clean_string, ' ')\n",
    "    clean.append(clean_string)\n",
    "  \n",
    "  return {\"clean\": clean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dotless_text(example):\n",
    "  dotless = []\n",
    "  for text in example[\"clean\"]:\n",
    "    dotless_chars = [letter_dict[char] for char in text]\n",
    "    dotless_string = ''.join(dotless_chars)\n",
    "        \n",
    "    dotless_string = replace(dotless_string, '_')\n",
    "    dotless.append(dotless_string)\n",
    "    \n",
    "  return {\"dotless\": dotless}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'ولا تنسى التسجيل معنا لتستفيد بكل جديد'} \n",
      "\n",
      "{'clean': ['و', 'ل', 'ا', '', 'ت', 'ن', 'س', 'ى', '', 'ا', 'ل', 'ت', 'س', 'ج', 'ي', 'ل', '', 'م', 'ع', 'ن', 'ا', '', 'ل', 'ت', 'س', 'ت', 'ف', 'ي', 'د', '', 'ب', 'ك', 'ل', '', 'ج', 'د', 'ي', 'د']} \n",
      "\n",
      "{'dotless': ['و', 'ل', 'ا', '', 'ب', 'ن', 'س', 'ى', '', 'ا', 'ل', 'ب', 'س', 'ح', 'ى', 'ل', '', 'م', 'ع', 'ن', 'ا', '', 'ل', 'ب', 'س', 'ب', 'ف', 'ى', 'د', '', 'ب', 'ك', 'ل', '', 'ح', 'د', 'ى', 'د']} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "text = {\"text\": \"ولا تنسى التسجيل معنا لتستفيد بكل جديد\"}\n",
    "print(text, \"\\n\")\n",
    "\n",
    "text = parse_clean_text(text)\n",
    "print(text, \"\\n\")\n",
    "\n",
    "text = parse_dotless_text(text)\n",
    "print(text, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for the datasets.filter() function to filter out examples/rows that have examples of less than 20 chars.\n",
    "#def filterEmpty(x):\n",
    "#    return not len(x['clean']) < 20\n",
    "\n",
    "#Not used, lambda function used instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading, saving, and trimming Oscar (unshuffled_deduplicated_ar) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the oscar unshuffled_deduplicated_ar dataset from huggingface \n",
    "#datasetLoad = load_dataset(\"oscar\", \"unshuffled_deduplicated_ar\") #Oscar Arabic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataset to \"ar-arrow-datasets/\" Apache Arrow datafolder\n",
    "#datasetLoad.save_to_disk('ar-arrow-datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load from file\n",
    "full_dataset = load_from_disk('/Users/ammar/Developer/git-repos/dotless/data/ar-arrow-datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'text'],\n",
      "        num_rows: 9006977\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(full_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying maps, filters, and splits\n",
    "This process of applying maps and filters is very slow especially for big datasets. \n",
    "\n",
    "It is possible to implement a batched approach similar ot batched tokenization that would speed it up greatly. \n",
    "\n",
    "In the .map() add perameter batched=True. However the function called needs to be compatible with this approach.\n",
    "\n",
    "I will implement this soon.\n",
    "\n",
    "Generally this is not the way to handle big data. However this is fine for the AR-dotless-small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the index of the #th space.\n",
    "def num_word(text, num):\n",
    "    space_count = 0\n",
    "    index = -1\n",
    "    for i in range(num):\n",
    "        index = text.find(' ', index + 1)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "exampleToWordsLen = [] # just to keep track of how many chunks an old  made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(exampleToWordsLen[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chunks examples into smaller examples, at @words_per_chuck words each\n",
    "def chunk_examples(examples, words_per_chunk=12): #previously 8\n",
    "    chunks = []\n",
    "    for sentence in examples[\"clean\"]:\n",
    "        words = sentence.split()\n",
    "        num_words = len(words)\n",
    "        exampleToWordsLen.append(math.ceil(num_words/words_per_chunk)) # just to keep track of how many chunks an old example made\n",
    "        start = 0\n",
    "        while start < num_words:\n",
    "            end = min(start + words_per_chunk, num_words)\n",
    "            chunk = ' '.join(words[start:end])\n",
    "            chunks.append(chunk)\n",
    "            start = end\n",
    "    \n",
    "    return {\"clean\": chunks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    #concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    concatenated_examples = {k: ''.join(examples[k]) for k in examples.keys()}\n",
    "\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of block_size.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 200000\n",
      "}) \n",
      "\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 200000\n",
      "}) \n",
      "\n",
      "Dataset({\n",
      "    features: ['clean'],\n",
      "    num_rows: 200000\n",
      "}) \n",
      "\n",
      "586 \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470f0bf8b22b442f820f85425ed19ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['clean'],\n",
      "    num_rows: 6108967\n",
      "}) \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c72f2f0b15b4e82bff0e01d6c3d05ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6108967 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['clean', 'dotless'],\n",
      "    num_rows: 6108967\n",
      "}) \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360d27f5e7364b6898ef405ca7b0376a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/6108967 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['clean', 'dotless'],\n",
      "    num_rows: 6060646\n",
      "}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = full_dataset['train'].select(range(200000)) #Trim to number of examples #previously 100,000\n",
    "dataset = dataset.remove_columns([\"id\"])\n",
    "print(dataset, '\\n')\n",
    "\n",
    "dataset = dataset.filter(lambda x: not len(x['text']) < 20) #Apply the filter to remove useless empty examples.\n",
    "print(dataset, '\\n')\n",
    "        \n",
    "dataset = dataset.map(parse_clean_text, batched=True, remove_columns=\"text\") #Apply the function (convert dotted to dotless)\n",
    "set_state_1 = dataset[\"clean\"][0]\n",
    "print(dataset, '\\n')\n",
    "\n",
    "# test to see how many examples are under 20 characters. Goal of filterEmpty() to eliminate\n",
    "a = 0\n",
    "for i in dataset['clean']:\n",
    "    if len(i) < 40:\n",
    "        a += 1\n",
    "print(a, '\\n')\n",
    "\n",
    "dataset = dataset.map(chunk_examples, batched=True, remove_columns=dataset.column_names) # applies the chuncking\n",
    "#dataset = dataset.map(group_texts, batched=True, num_proc=4, remove_columns=dataset.column_names) \n",
    "\n",
    "set_state_2 = dataset[\"clean\"][0:exampleToWordsLen[0]]\n",
    "#set_state_2 = dataset[\"clean\"]\n",
    "\n",
    "print(dataset, '\\n')\n",
    "\n",
    "dataset = dataset.map(parse_dotless_text, batched=True) #Apply the function (convert dotted to dotless)\n",
    "set_state_3 = dataset[\"dotless\"][0:exampleToWordsLen[0]]\n",
    "#set_state_3 = dataset[\"dotless\"]\n",
    "\n",
    "print(dataset, '\\n')\n",
    "\n",
    "dataset = dataset.filter(lambda x: not len(x['clean']) < 20) #Apply the filter to remove useless empty examples.\n",
    "print(dataset, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مرحبا بك عزيز الزائر نتمنى لك أوقاتا سعيدة معنا وأن نزداد شرفا بخدمتك ولا تنسى التسجيل معنا لتستفيد بكل جديدأهلا وسهلا بك زائرنا الكريم أنت لم تقم بتسجيل الدخول بعد يشرفنا أن تقوم بالدخول أو التسجيل إذا رغبت بالمشاركة في المنتدىنرحب بكل الزائرين ونتمى لكم قضا وقت ممتع معنا يملأه الحب والود والاستفادة المتبادلة بيننا علميا وعمليا يسعدنا تسجيلكم معنا ومشاركتنا وشعارنا دوما نحب الخير لكل الناس مهما اختلفت الألوان والديانات والأجناس لي أربع شقيقات أنا أكثرهن غنى لكن لا أدري لماذا يأتي أقاربي لزيارة أخواتي بكثرةوحينما يأتي موعد زيارتي لا يأتي سوى القليلفهم يزورون أخواتي الأربع كل يومأماأنا أكثر أخواتي عطا لمن يأتيني لا أتهم أخواتي بالتقصير أبدا ولكن الكل يعرف أني أكثرهن عطاكثيرون ينصحون أقاربي بأن يأتوني فلدي خير كثير وأعطي بكرم من يأتيني ومع ذلك يبتعدون عني فلا حياة لمن تنادي اختر منتدىقناة عجباوي التلفزيونية التسويقية البرامج التلفزيونية لقناة عجباوي التسويقية تعرف على عجباوي سيرة ذاتية سابقة أعمال أرشيف تصميمات عجباوي إعلانات الشركات والمحلات أغلفة كتب تنسيقات المتن الداخلي للكتب الدفاتر والمستندات اللافتات الإعلانية السريلات والأختام والأكلشيهات برشور فلاير ستيكر منتجات كتالوجات بوستر كروت شخصية شركات أفراح ومناسبات إمساكيات رمضان عجباوي مول سوق تجاري وخدمات متكاملة بيت التحف والهدايا تحف وأنتيكات حفر ليزر إعلانات وظائف وظائف مطلوبة وظائف معروضة إعلانات مجانية خدمات المكاتب الإدارية خدمات الشركات الصناعية خدمات زراعية خدمات احداث ومناسبات خدمات شخصية خدمات منزلية بنا وعقارات مبيعات تسويق مالية واقتصادية إعلام ونشر خدمات تعليمية رحلات وترفيه رياضة سيارات ومركبات صحة مواد غذائية عجباوي مصمم جرافيك مجموعة برامج الجرافيك الفوتوشوب الكوريل درو اليستريتور الدريم وييفر الفلاش والسويش أدوات المصمم مجموعة برامج الأوفيس تعليم الأكسيس تعليم الوورد تعليم الإكسل أسرار وفنيات عالم الطباعة والنشر تصاميم الأعضا منتدى البرامج والعاب الكمبيوتروالمحمول عجباوي مهندس صيانة الأسئلة والاستفسارات منتدى برامج الكمبيوتر منتدى برامج الحمايه للكمبيوتر منتدى الخلفيات والثيمات والايقونات لجهاز الكمبيوتر منتدى شرح البرامج وتبادل خبرات الكمبيوتر منتدى برامج الملتيميديا والفيديو منتدى العاب الكمبيوتر منتدى الستالايت والقنوات الفضائية والترددات للمحطات منتدى الجوال برامج جوال منتدى رسائل الجوال اغاني وكليبات ونغمات للجوال منتدى التنمية البشرية وتطوير الذات منتدى الأستاذ الدكتور هشام الشريف التنمية البشرية وتطوير مهارات الذات الموارد البشرية والتنمية الإدارية منتدى الحسابات المالية المنتدى التعليمي معلم الأجيال الأستاذ يحيى خضر رسالة إلى رجال التعليم حوار مع طلاب العلم درس خصوصي مرحلة رياض الأطفال المرحلة الإبتدائية الصف الأول الإبتدائي الصف الثاني الإبتدائي الصف الثالث الإبتدائي الصف الرابع الإبتدائي الصف الخامس الإبتدائي الصف السادس الإبتدائي المرحلة الإعدادية الصف الأول الإعدادي الصف الثاني الإعدادي الصف الثالث الإعدادي المرحلة الثانوية الصف الأول الثانوي الصف الثاني الثانوي الصف الثالث الثانوي مرحلة التعليم الفني العالي مرحلة التعليم الجامعي الأعمال الأدبية للأستاذ يحيى خضر عجباوي والأسرة والمجتمع والناس فن الحياة الزوجية السعيدة العلاقة الزوجية الحميمة الأسرة والطفل منتدى المرأة الحامل والطفل منتدى صحة و مستلزمات الطفل منتدى اناقة الرجل منتدى المرأة والزينة منتدى الاشغال والاعمال اليدوية منتدى الخياطة والتطريز منتدى المطبخ والمأكولات المنتدى الطبي أريد حلا منتدى التهنئة والاهداات المنتدى الأدبي عجباوي فنان المقامات الموسيقية العربية منتدى دروس نظرية في الموسيقى الايقاع النغم النوتة الموسيقية الشاعر الكبير أحمد فؤاد نجم منتدى الشاعر الموهوب وحيد الدهشان الشاعرة المبدعة إيمان بكري موضوعات أدبية عامة منتدى الغنا الراقي زمن الفن الجميل إبداعات الأعضا عمالقة الفن والمقطوعات والسماعيات الموسيقيه والمعزوفات النادرة المنتدى العام للقصص والروايات الكتب منتدى البحوث الأكاديمية منتدى المسرح المنتدى الإسلامي القرآن الكريم نور البيان في تعليم القراة بالقرآن الأحاديث النبوية الشريفة ركن شهر رمضان المبارك منتدى الصوتيات والاناشيد الاسلامية منتدى الفيديو الإسلامي أخبار العالم الإسلامي موضوعات إسلامية عامة مشروع علم ينتفع به وقف لله تعالى دروس في العقيدة تربية الأبنا منتدى الموضوعات العامة منتدى علم النفس علم النفس دراسات علم النفس كتب علم النفس ابحاث علم النفس منتدى تفسير الاحلام منتدى علوم الفلك والابراج منتدى السياحة والسفر منتدى عجباوي للحوار الجاد منتدى الحوادث جرائم قتل فضائح أخبار مشاكل وقضايا موضوعات علمية منتدى الشخصيات التاريخية عجباوي الرياضي منتدى الملتيميديا عجباوي تيوب منتدى الصور منتدى الفنون الجميلة وابداعات الاعضا منتدى صيد الكاميرا منتدى الكاريكاتير منتدى الأفلام والمسلسلات والمسرحيات عجباوي قاعد فاضي نكت طرائف ضحك فرفشة منتدى الضحك والفرفشة منتدى الالغاز والمسابقات منتدى الالعاب الارشيف والمواضيع القديمة منتدى مجاني منتدى مجاني للدعم و المساعدة إتصل بنا التبليغ عن محتوى مخالف انشئ مدونة مجانيا عند التصوير يقوم الالة بمسح الاصول مرة واحده وتخزينها بالذاكره ثم تتم عملية التصوير لاي عدد من النسخ منتدى مجاني منتدى مجاني للدعم و المساعدة إتصل بنا التبليغ عن محتوى مخالف الحصول على مدونة \n",
      "\n",
      "\n",
      "['مرحبا بك عزيز الزائر نتمنى لك أوقاتا سعيدة معنا وأن نزداد شرفا', 'بخدمتك ولا تنسى التسجيل معنا لتستفيد بكل جديدأهلا وسهلا بك زائرنا الكريم', 'أنت لم تقم بتسجيل الدخول بعد يشرفنا أن تقوم بالدخول أو التسجيل', 'إذا رغبت بالمشاركة في المنتدىنرحب بكل الزائرين ونتمى لكم قضا وقت ممتع', 'معنا يملأه الحب والود والاستفادة المتبادلة بيننا علميا وعمليا يسعدنا تسجيلكم معنا', 'ومشاركتنا وشعارنا دوما نحب الخير لكل الناس مهما اختلفت الألوان والديانات والأجناس', 'لي أربع شقيقات أنا أكثرهن غنى لكن لا أدري لماذا يأتي أقاربي', 'لزيارة أخواتي بكثرةوحينما يأتي موعد زيارتي لا يأتي سوى القليلفهم يزورون أخواتي', 'الأربع كل يومأماأنا أكثر أخواتي عطا لمن يأتيني لا أتهم أخواتي بالتقصير', 'أبدا ولكن الكل يعرف أني أكثرهن عطاكثيرون ينصحون أقاربي بأن يأتوني فلدي', 'خير كثير وأعطي بكرم من يأتيني ومع ذلك يبتعدون عني فلا حياة', 'لمن تنادي اختر منتدىقناة عجباوي التلفزيونية التسويقية البرامج التلفزيونية لقناة عجباوي التسويقية', 'تعرف على عجباوي سيرة ذاتية سابقة أعمال أرشيف تصميمات عجباوي إعلانات الشركات', 'والمحلات أغلفة كتب تنسيقات المتن الداخلي للكتب الدفاتر والمستندات اللافتات الإعلانية السريلات', 'والأختام والأكلشيهات برشور فلاير ستيكر منتجات كتالوجات بوستر كروت شخصية شركات أفراح', 'ومناسبات إمساكيات رمضان عجباوي مول سوق تجاري وخدمات متكاملة بيت التحف والهدايا', 'تحف وأنتيكات حفر ليزر إعلانات وظائف وظائف مطلوبة وظائف معروضة إعلانات مجانية', 'خدمات المكاتب الإدارية خدمات الشركات الصناعية خدمات زراعية خدمات احداث ومناسبات خدمات', 'شخصية خدمات منزلية بنا وعقارات مبيعات تسويق مالية واقتصادية إعلام ونشر خدمات', 'تعليمية رحلات وترفيه رياضة سيارات ومركبات صحة مواد غذائية عجباوي مصمم جرافيك', 'مجموعة برامج الجرافيك الفوتوشوب الكوريل درو اليستريتور الدريم وييفر الفلاش والسويش أدوات', 'المصمم مجموعة برامج الأوفيس تعليم الأكسيس تعليم الوورد تعليم الإكسل أسرار وفنيات', 'عالم الطباعة والنشر تصاميم الأعضا منتدى البرامج والعاب الكمبيوتروالمحمول عجباوي مهندس صيانة', 'الأسئلة والاستفسارات منتدى برامج الكمبيوتر منتدى برامج الحمايه للكمبيوتر منتدى الخلفيات والثيمات', 'والايقونات لجهاز الكمبيوتر منتدى شرح البرامج وتبادل خبرات الكمبيوتر منتدى برامج الملتيميديا', 'والفيديو منتدى العاب الكمبيوتر منتدى الستالايت والقنوات الفضائية والترددات للمحطات منتدى الجوال', 'برامج جوال منتدى رسائل الجوال اغاني وكليبات ونغمات للجوال منتدى التنمية البشرية', 'وتطوير الذات منتدى الأستاذ الدكتور هشام الشريف التنمية البشرية وتطوير مهارات الذات', 'الموارد البشرية والتنمية الإدارية منتدى الحسابات المالية المنتدى التعليمي معلم الأجيال الأستاذ', 'يحيى خضر رسالة إلى رجال التعليم حوار مع طلاب العلم درس خصوصي', 'مرحلة رياض الأطفال المرحلة الإبتدائية الصف الأول الإبتدائي الصف الثاني الإبتدائي الصف', 'الثالث الإبتدائي الصف الرابع الإبتدائي الصف الخامس الإبتدائي الصف السادس الإبتدائي المرحلة', 'الإعدادية الصف الأول الإعدادي الصف الثاني الإعدادي الصف الثالث الإعدادي المرحلة الثانوية', 'الصف الأول الثانوي الصف الثاني الثانوي الصف الثالث الثانوي مرحلة التعليم الفني', 'العالي مرحلة التعليم الجامعي الأعمال الأدبية للأستاذ يحيى خضر عجباوي والأسرة والمجتمع', 'والناس فن الحياة الزوجية السعيدة العلاقة الزوجية الحميمة الأسرة والطفل منتدى المرأة', 'الحامل والطفل منتدى صحة و مستلزمات الطفل منتدى اناقة الرجل منتدى المرأة', 'والزينة منتدى الاشغال والاعمال اليدوية منتدى الخياطة والتطريز منتدى المطبخ والمأكولات المنتدى', 'الطبي أريد حلا منتدى التهنئة والاهداات المنتدى الأدبي عجباوي فنان المقامات الموسيقية', 'العربية منتدى دروس نظرية في الموسيقى الايقاع النغم النوتة الموسيقية الشاعر الكبير', 'أحمد فؤاد نجم منتدى الشاعر الموهوب وحيد الدهشان الشاعرة المبدعة إيمان بكري', 'موضوعات أدبية عامة منتدى الغنا الراقي زمن الفن الجميل إبداعات الأعضا عمالقة', 'الفن والمقطوعات والسماعيات الموسيقيه والمعزوفات النادرة المنتدى العام للقصص والروايات الكتب منتدى', 'البحوث الأكاديمية منتدى المسرح المنتدى الإسلامي القرآن الكريم نور البيان في تعليم', 'القراة بالقرآن الأحاديث النبوية الشريفة ركن شهر رمضان المبارك منتدى الصوتيات والاناشيد', 'الاسلامية منتدى الفيديو الإسلامي أخبار العالم الإسلامي موضوعات إسلامية عامة مشروع علم', 'ينتفع به وقف لله تعالى دروس في العقيدة تربية الأبنا منتدى الموضوعات', 'العامة منتدى علم النفس علم النفس دراسات علم النفس كتب علم النفس', 'ابحاث علم النفس منتدى تفسير الاحلام منتدى علوم الفلك والابراج منتدى السياحة', 'والسفر منتدى عجباوي للحوار الجاد منتدى الحوادث جرائم قتل فضائح أخبار مشاكل', 'وقضايا موضوعات علمية منتدى الشخصيات التاريخية عجباوي الرياضي منتدى الملتيميديا عجباوي تيوب', 'منتدى الصور منتدى الفنون الجميلة وابداعات الاعضا منتدى صيد الكاميرا منتدى الكاريكاتير', 'منتدى الأفلام والمسلسلات والمسرحيات عجباوي قاعد فاضي نكت طرائف ضحك فرفشة منتدى', 'الضحك والفرفشة منتدى الالغاز والمسابقات منتدى الالعاب الارشيف والمواضيع القديمة منتدى مجاني', 'منتدى مجاني للدعم و المساعدة إتصل بنا التبليغ عن محتوى مخالف انشئ', 'مدونة مجانيا عند التصوير يقوم الالة بمسح الاصول مرة واحده وتخزينها بالذاكره', 'ثم تتم عملية التصوير لاي عدد من النسخ منتدى مجاني منتدى مجاني', 'للدعم و المساعدة إتصل بنا التبليغ عن محتوى مخالف الحصول على مدونة', 'ش سورة الفاتحة سورة البقرة سورة آل عمران سورة النسا سورةالمائدة سورة', 'الانعام سورة الاعراف سورة الأ نفال سورةالتوبة سورة يونس سورة هود سورة', 'يوسف سورة الرعد سورة أبراهيم سورةالحجر سورةالنحل سورة الاسرا سورةالكهف سورة مريم', 'سورة طه سورة الأنبيا سورة الحج سورة المؤمنون سورة النور سورة الفرقان', 'سورة الشعرا سورة النمل سورة القصص سورة العنكبوت سورة الروم سورة لقمان', 'سورة السجدة سورة الأحزاب سورة سبأ سورة فاطر سورة يس سورة الصافات', 'سورة ص سورة الزمر سورة غافر سورة فصلت سورة الشورى سورة الزخرف', 'سورة الدخان سورة الجاثية سورةالأحقاف سورة محمد سورةالفتح سورةالحجرات سورة ق سورةالذاريات', 'سورةالطور سورةالنجم سورةالقمر سورةالرحمن سورةالواقعة سورةالحديد سورةالمجادلة سورة الحشر سورة الممتحنة سورة', 'الصف سورة الجمعة سورة المنافقون سورة التغابن سورة الطلاق سورة التحريم سورة', 'الملك سورة القلم سورة الحاقة سورة المعارج سورة نوح سورة الجن سورة', 'المزمل سورة المدثر سورة القيامة سورة الإنسان سورةالمرسلات سورة النبإ سورةالنازعات سورة', 'عبس سورة التكوير سورة الانفطار سورة المطففين سورة الانشقاق سورة البروج سورة', 'الطارق سورة الأعلى سورة الغاشية سورة الفجر سورة البلد سورة الشمس سورة', 'الليل سورة الضحى سورة الشرح سورة التين سورة العلق سورة القدر سورة', 'البينة سورة الزلزلة سورة العاديات سورة القارعة سورة التكاثر سورة العصر سورة', 'الهمزة سورة الفيل سورة قريش سورة الماعون سورة الكوثر سورة الكافرون سورة', 'النصر سورة المسد سورة الإخلاص سورة الفلق سورة الناسالحلقة الخامسة عشر فمن', 'حاجك فيه من بعد ما جاك من العلم فقل تعالوا ندع أبنانا', 'و أبناكم و نسانا و نساكم و أنفسنا و أنفسكم ثم نبتهل', 'فنجعل لالحلقة التاسعة حتى إذا أتوا على وادي النمل قالت نملة يا', 'أيها النمل ادخلوا مساكنكم لا يحطمنكم سليمان وجنوده وهم لا يشعرون خطبة', 'جمعة آمتنا فى الآونة الأخيرة يتناول فيها فضيلة الشيخرحمه الله ثلاث مواضيع', 'سب النبى صلى الله عليه وسلم والإساة إليه موت عدد كبير جرا', 'الإهمال نقص فى الاموال إنفلونزا الطيور', 'الزلابية من الحلويات الشهية و الذيذة التى يحبونها الأطفال والصغار لأنها هشه', 'وجميلة والبعض يفضلون أكلها باردة وآخرين يفضلونها ساخنة مع مشروبك المفضلاليوم سنتعرف', 'على طريقة إعداد الزلابية فى مطبخك بطريقة ناجحة وبسيطةإخلطى الدقيق مع الملح', 'والنشا والخميرة والسكر والفانيليا ثم أضيفى مقدار من الما وقلبى الخليط جيدا'] \n",
      "\n",
      "\n",
      "['مرحبا بك عرىر الراىر نبمنى لك اوفابا سعىده معنا وان نرداد سرفا', 'بحدمبك ولا بنسى البسحىل معنا لبسبفىد بكل حدىداهلا وسهلا بك راىرنا الكرىم', 'انب لم بفم ببسحىل الدحول بعد ىسرفنا ان بفوم بالدحول او البسحىل', 'ادا رعبب بالمساركه فى المنبدىنرحب بكل الراىرىن ونبمى لكم فصا وفب ممبع', 'معنا ىملاه الحب والود والاسبفاده المببادله بىننا علمىا وعملىا ىسعدنا بسحىلكم معنا', 'ومساركبنا وسعارنا دوما نحب الحىر لكل الناس مهما احبلفب الالوان والدىاناب والاحناس', 'لى اربع سفىفاب انا اكبرهن عنى لكن لا ادرى لمادا ىابى افاربى', 'لرىاره احوابى بكبرهوحىنما ىابى موعد رىاربى لا ىابى سوى الفلىلفهم ىرورون احوابى', 'الاربع كل ىوماماانا اكبر احوابى عطا لمن ىابىنى لا ابهم احوابى بالبفصىر', 'ابدا ولكن الكل ىعرف انى اكبرهن عطاكبىرون ىنصحون افاربى بان ىابونى فلدى', 'حىر كبىر واعطى بكرم من ىابىنى ومع دلك ىببعدون عنى فلا حىاه', 'لمن بنادى احبر منبدىفناه عحباوى البلفرىونىه البسوىفىه البرامح البلفرىونىه لفناه عحباوى البسوىفىه', 'بعرف على عحباوى سىره دابىه سابفه اعمال ارسىف بصمىماب عحباوى اعلاناب السركاب', 'والمحلاب اعلفه كبب بنسىفاب المبن الداحلى للكبب الدفابر والمسبنداب اللافباب الاعلانىه السرىلاب', 'والاحبام والاكلسىهاب برسور فلاىر سبىكر منبحاب كبالوحاب بوسبر كروب سحصىه سركاب افراح', 'ومناسباب امساكىاب رمصان عحباوى مول سوف بحارى وحدماب مبكامله بىب البحف والهداىا', 'بحف وانبىكاب حفر لىرر اعلاناب وطاىف وطاىف مطلوبه وطاىف معروصه اعلاناب محانىه', 'حدماب المكابب الادارىه حدماب السركاب الصناعىه حدماب رراعىه حدماب احداب ومناسباب حدماب', 'سحصىه حدماب منرلىه بنا وعفاراب مبىعاب بسوىف مالىه وافبصادىه اعلام ونسر حدماب', 'بعلىمىه رحلاب وبرفىه رىاصه سىاراب ومركباب صحه مواد عداىىه عحباوى مصمم حرافىك', 'محموعه برامح الحرافىك الفوبوسوب الكورىل درو الىسبرىبور الدرىم وىىفر الفلاس والسوىس ادواب', 'المصمم محموعه برامح الاوفىس بعلىم الاكسىس بعلىم الوورد بعلىم الاكسل اسرار وفنىاب', 'عالم الطباعه والنسر بصامىم الاعصا منبدى البرامح والعاب الكمبىوبروالمحمول عحباوى مهندس صىانه', 'الاسىله والاسبفساراب منبدى برامح الكمبىوبر منبدى برامح الحماىه للكمبىوبر منبدى الحلفىاب والبىماب', 'والاىفوناب لحهار الكمبىوبر منبدى سرح البرامح وببادل حبراب الكمبىوبر منبدى برامح الملبىمىدىا', 'والفىدىو منبدى العاب الكمبىوبر منبدى السبالاىب والفنواب الفصاىىه والبردداب للمحطاب منبدى الحوال', 'برامح حوال منبدى رساىل الحوال اعانى وكلىباب ونعماب للحوال منبدى البنمىه البسرىه', 'وبطوىر الداب منبدى الاسباد الدكبور هسام السرىف البنمىه البسرىه وبطوىر مهاراب الداب', 'الموارد البسرىه والبنمىه الادارىه منبدى الحساباب المالىه المنبدى البعلىمى معلم الاحىال الاسباد', 'ىحىى حصر رساله الى رحال البعلىم حوار مع طلاب العلم درس حصوصى', 'مرحله رىاص الاطفال المرحله الاببداىىه الصف الاول الاببداىى الصف البانى الاببداىى الصف', 'البالب الاببداىى الصف الرابع الاببداىى الصف الحامس الاببداىى الصف السادس الاببداىى المرحله', 'الاعدادىه الصف الاول الاعدادى الصف البانى الاعدادى الصف البالب الاعدادى المرحله البانوىه', 'الصف الاول البانوى الصف البانى البانوى الصف البالب البانوى مرحله البعلىم الفنى', 'العالى مرحله البعلىم الحامعى الاعمال الادبىه للاسباد ىحىى حصر عحباوى والاسره والمحبمع', 'والناس فن الحىاه الروحىه السعىده العلافه الروحىه الحمىمه الاسره والطفل منبدى المراه', 'الحامل والطفل منبدى صحه و مسبلرماب الطفل منبدى انافه الرحل منبدى المراه', 'والرىنه منبدى الاسعال والاعمال الىدوىه منبدى الحىاطه والبطرىر منبدى المطبح والماكولاب المنبدى', 'الطبى ارىد حلا منبدى البهنىه والاهدااب المنبدى الادبى عحباوى فنان المفاماب الموسىفىه', 'العربىه منبدى دروس نطرىه فى الموسىفى الاىفاع النعم النوبه الموسىفىه الساعر الكبىر', 'احمد فواد نحم منبدى الساعر الموهوب وحىد الدهسان الساعره المبدعه اىمان بكرى', 'موصوعاب ادبىه عامه منبدى العنا الرافى رمن الفن الحمىل ابداعاب الاعصا عمالفه', 'الفن والمفطوعاب والسماعىاب الموسىفىه والمعروفاب النادره المنبدى العام للفصص والرواىاب الكبب منبدى', 'البحوب الاكادىمىه منبدى المسرح المنبدى الاسلامى الفران الكرىم نور البىان فى بعلىم', 'الفراه بالفران الاحادىب النبوىه السرىفه ركن سهر رمصان المبارك منبدى الصوبىاب والاناسىد', 'الاسلامىه منبدى الفىدىو الاسلامى احبار العالم الاسلامى موصوعاب اسلامىه عامه مسروع علم', 'ىنبفع به وفف لله بعالى دروس فى العفىده بربىه الابنا منبدى الموصوعاب', 'العامه منبدى علم النفس علم النفس دراساب علم النفس كبب علم النفس', 'ابحاب علم النفس منبدى بفسىر الاحلام منبدى علوم الفلك والابراح منبدى السىاحه', 'والسفر منبدى عحباوى للحوار الحاد منبدى الحوادب حراىم فبل فصاىح احبار مساكل', 'وفصاىا موصوعاب علمىه منبدى السحصىاب البارىحىه عحباوى الرىاصى منبدى الملبىمىدىا عحباوى بىوب', 'منبدى الصور منبدى الفنون الحمىله وابداعاب الاعصا منبدى صىد الكامىرا منبدى الكارىكابىر', 'منبدى الافلام والمسلسلاب والمسرحىاب عحباوى فاعد فاصى نكب طراىف صحك فرفسه منبدى', 'الصحك والفرفسه منبدى الالعار والمسابفاب منبدى الالعاب الارسىف والمواصىع الفدىمه منبدى محانى', 'منبدى محانى للدعم و المساعده ابصل بنا الببلىع عن محبوى محالف انسى', 'مدونه محانىا عند البصوىر ىفوم الاله بمسح الاصول مره واحده وبحرىنها بالداكره', 'بم ببم عملىه البصوىر لاى عدد من النسح منبدى محانى منبدى محانى', 'للدعم و المساعده ابصل بنا الببلىع عن محبوى محالف الحصول على مدونه', 'س سوره الفابحه سوره البفره سوره ال عمران سوره النسا سورهالماىده سوره', 'الانعام سوره الاعراف سوره الا نفال سورهالبوبه سوره ىونس سوره هود سوره', 'ىوسف سوره الرعد سوره ابراهىم سورهالححر سورهالنحل سوره الاسرا سورهالكهف سوره مرىم', 'سوره طه سوره الانبىا سوره الحح سوره المومنون سوره النور سوره الفرفان', 'سوره السعرا سوره النمل سوره الفصص سوره العنكبوب سوره الروم سوره لفمان', 'سوره السحده سوره الاحراب سوره سبا سوره فاطر سوره ىس سوره الصافاب', 'سوره ص سوره الرمر سوره عافر سوره فصلب سوره السورى سوره الرحرف', 'سوره الدحان سوره الحابىه سورهالاحفاف سوره محمد سورهالفبح سورهالححراب سوره ف سورهالدارىاب', 'سورهالطور سورهالنحم سورهالفمر سورهالرحمن سورهالوافعه سورهالحدىد سورهالمحادله سوره الحسر سوره الممبحنه سوره', 'الصف سوره الحمعه سوره المناففون سوره البعابن سوره الطلاف سوره البحرىم سوره', 'الملك سوره الفلم سوره الحافه سوره المعارح سوره نوح سوره الحن سوره', 'المرمل سوره المدبر سوره الفىامه سوره الانسان سورهالمرسلاب سوره النبا سورهالنارعاب سوره', 'عبس سوره البكوىر سوره الانفطار سوره المطففىن سوره الانسفاف سوره البروح سوره', 'الطارف سوره الاعلى سوره العاسىه سوره الفحر سوره البلد سوره السمس سوره', 'اللىل سوره الصحى سوره السرح سوره البىن سوره العلف سوره الفدر سوره', 'البىنه سوره الرلرله سوره العادىاب سوره الفارعه سوره البكابر سوره العصر سوره', 'الهمره سوره الفىل سوره فرىس سوره الماعون سوره الكوبر سوره الكافرون سوره', 'النصر سوره المسد سوره الاحلاص سوره الفلف سوره الناسالحلفه الحامسه عسر فمن', 'حاحك فىه من بعد ما حاك من العلم ففل بعالوا ندع ابنانا', 'و ابناكم و نسانا و نساكم و انفسنا و انفسكم بم نببهل', 'فنحعل لالحلفه الباسعه حبى ادا ابوا على وادى النمل فالب نمله ىا', 'اىها النمل ادحلوا مساكنكم لا ىحطمنكم سلىمان وحنوده وهم لا ىسعرون حطبه', 'حمعه امبنا فى الاونه الاحىره ىبناول فىها فصىله السىحرحمه الله بلاب مواصىع', 'سب النبى صلى الله علىه وسلم والاساه الىه موب عدد كبىر حرا', 'الاهمال نفص فى الاموال انفلونرا الطىور', 'الرلابىه من الحلوىاب السهىه و الدىده البى ىحبونها الاطفال والصعار لانها هسه', 'وحمىله والبعص ىفصلون اكلها بارده واحرىن ىفصلونها ساحنه مع مسروبك المفصلالىوم سنبعرف', 'على طرىفه اعداد الرلابىه فى مطبحك بطرىفه ناححه وبسىطهاحلطى الدفىف مع الملح', 'والنسا والحمىره والسكر والفانىلىا بم اصىفى مفدار من الما وفلبى الحلىط حىدا']\n"
     ]
    }
   ],
   "source": [
    "print(set_state_1,\"\\n\\n\")\n",
    "print(set_state_2,\"\\n\\n\")\n",
    "print(set_state_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test to see how many examples are under 20 characters. Goal of filterEmpty() to eliminate\n",
    "a = 0\n",
    "for i in dataset['clean']:\n",
    "    if len(i) < 20:\n",
    "        a += 1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['clean', 'dotless'],\n",
       "        num_rows: 6060645\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clean = dataset.train_test_split(train_size= 0.999999999) #create 80/20 split into train and test datasets\n",
    "del dataset_clean['test'] # no longer using a test set\n",
    "dataset_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['clean', 'dotless'],\n",
       "        num_rows: 6060645\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and upload to hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec627dca2c9f42dea3587c9129fefeec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/4 shards):   0%|          | 0/6060645 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#save the cleaned dataset to \"clean-arrow-datasets/\" Apache Arrow datafolder\n",
    "dataset_clean.save_to_disk(\"AR-dotless-2MediumPlus-arrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required token id. Run 'huggingface-cli login'\n",
    "#dataset_clean.push_to_hub(\"dot-ammar/AR-dotless-2MediumPlus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
