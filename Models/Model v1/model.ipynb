{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_dict_with_duplicates(input_dict):\n",
    "    reversed_dict = {}\n",
    "    \n",
    "    for key, value in input_dict.items():\n",
    "        if value not in reversed_dict:\n",
    "            reversed_dict[value] = [key]\n",
    "        else:\n",
    "            reversed_dict[value].append(key)\n",
    "    \n",
    "    return reversed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_dict = {\n",
    "    \"ا\": \"ا\",\n",
    "    \"أ\": \"ا\",\n",
    "    \"إ\": \"ا\",\n",
    "    \"آ\": \"ا\",\n",
    "    \"ب\": \"ب\",\n",
    "    \"ت\": \"ب\",\n",
    "    \"ث\": \"ب\",\n",
    "    \"ج\": \"ح\",\n",
    "    \"ح\": \"ح\",\n",
    "    \"خ\": \"ح\",\n",
    "    \"د\": \"د\",\n",
    "    \"ذ\": \"د\",\n",
    "    \"ر\": \"ر\",\n",
    "    \"ز\": \"ر\",\n",
    "    \"س\": \"س\",\n",
    "    \"ش\": \"س\",\n",
    "    \"ص\": \"ص\",\n",
    "    \"ض\": \"ص\",\n",
    "    \"ط\": \"ط\",\n",
    "    \"ظ\": \"ط\",\n",
    "    \"ع\": \"ع\",\n",
    "    \"غ\": \"ع\",\n",
    "    \"ف\": \"ف\",\n",
    "    \"ق\": \"ف\",\n",
    "    \"ك\": \"ك\",\n",
    "    \"ل\": \"ل\",\n",
    "    \"م\": \"م\",\n",
    "    \"ن\": \"ن\",\n",
    "    \"و\": \"و\",\n",
    "    \"ؤ\": \"و\",\n",
    "    \"ه\": \"ه\",\n",
    "    \"ة\": \"ه\",\n",
    "    \"ي\": \"ى\",\n",
    "    \"ى\": \"ى\",\n",
    "    \"ئ\": \"ى\",\n",
    "    \" \": \" \",\n",
    "}\n",
    "letter_set = set(letter_dict.keys())\n",
    "iLetters = reverse_dict_with_duplicates(letter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces multiple spaces, or whatever char designated by the perameter into one char. (helper function)\n",
    "def replace(string, char):\n",
    "    while char+char in string:\n",
    "        string = string.replace(char+char, char)\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text(text):\n",
    "    \n",
    "  text = text.strip(\" \")\n",
    "  \n",
    "  clean_chars = [char for char in text if char in letter_set]\n",
    "  clean_string = ''.join(clean_chars)\n",
    "\n",
    "  dotless_chars = [letter_dict[char] for char in clean_chars]\n",
    "  dotless_string = ''.join(dotless_chars)\n",
    "      \n",
    "  clean_string = replace(clean_string, ' ')\n",
    "  dotless_string = replace(dotless_string, '_')\n",
    "  \n",
    "  return {\"clean\": clean_string, \"dotless\": dotless_string}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arabic wordlist into set\n",
    "#with open('arabic-wordlist-1.6.txt', 'r') as f:\n",
    "   # dictionary = set(f.read().splitlines())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allVariation(root, check, i = 0 ):\n",
    "    tWord = []\n",
    "    word = [a for a in root]\n",
    "    char = word[i]\n",
    "    for dot in iLetters[char]:\n",
    "        word[i] = dot\n",
    "        vWord = ''.join(word)\n",
    "        if i != len(word) - 1:\n",
    "            tWord.extend(allVariation(vWord, check, i+1))\n",
    "        else:\n",
    "            if check == False:\n",
    "                tWord.append(vWord)\n",
    "            elif vWord in dictionary:\n",
    "                tWord.append(vWord)\n",
    "    return tWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_different_indices(str1, str2):\n",
    "    # Initialize an empty list to store the different indices\n",
    "    different_indices = []\n",
    "\n",
    "    # Iterate through the characters of the strings\n",
    "    for i in range(min(len(str1), len(str2))):\n",
    "        if str1[i] != str2[i]:\n",
    "            different_indices.append(i)\n",
    "\n",
    "    # If one string is longer than the other, consider the remaining characters as different\n",
    "    for i in range(min(len(str1), len(str2)), max(len(str1), len(str2))):\n",
    "        different_indices.append(i)\n",
    "\n",
    "    return different_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at dot-ammar/dotless_model-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(model=\"dot-ammar/dotless_model-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translator.save_pretrained('dotless-model-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (dotless): ىا اىها الدىن امنوا لا بسالوا عن اسىا ان ببد لكم بسوكم وان بسالوا عنها حىن\n",
      "Target (clean):  يا أيها الذين آمنوا لا تسألوا عن أشيا إن تبد لكم تسؤكم وإن تسألوا عنها حين\n",
      "Output (dotted): يا أيها الذين آمنوا لا تسألوا عن آسيا أن ببد لكم تشوكم وأن تسألوا عنها حين\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[33, 34, 38, 41, 50, 51, 56]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = parse_text(\" يَا أَيُّهَا الَّذِينَ آمَنُوا لَا تَسْأَلُوا عَنْ أَشْيَاءَ إِن تُبْدَ لَكُمْ تَسُؤْكُمْ وَإِن تَسْأَلُوا عَنْهَا حِينَ\")\n",
    "testDotless = test[\"dotless\"]\n",
    "testClean = test[\"clean\"]\n",
    "testOutput = translator(testDotless)[0]['generated_text']\n",
    "\n",
    "print(\"Input (dotless): \" + testDotless)\n",
    "print(\"Target (clean):  \" + testClean)\n",
    "print(\"Output (dotted): \" + testOutput)\n",
    "\n",
    "find_different_indices(testClean, testOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = \"فرا احمد الفران\"\n",
    "example2 = \"لبسبفىد بكل حدىد\"\n",
    "example3 = \"لدىنا عبر نرسل معلوماب الححر عبر البرىد الالكبرونى\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'قرأ أحمد القرآن'}]\n",
      "[{'generated_text': 'لتس اشت بكل جديد'}]\n",
      "[{'generated_text': 'لدينا عبر نرسل معلومات الحجر عبر البريد الإلكتروني'}]\n"
     ]
    }
   ],
   "source": [
    "out_example1 = translator(example1)\n",
    "out_example2 = translator(example2)\n",
    "out_example3 = translator(example3)\n",
    "\n",
    "print(out_example1)\n",
    "print(out_example2)\n",
    "print(out_example3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Example 1:\n",
    "فرا احمد الفران\n",
    "\n",
    "Example 2:\n",
    "لبسبفىد بكل حدىد\n",
    "\n",
    "Example 3:\n",
    "لدىنا عبر نرسل معلوماب الححر عبر البرىد الالكبرونى\n",
    "\n",
    "\n",
    "--------------------------------------\n",
    "Train Loss: 7.4848\n",
    "Validation Loss: 6.8419\n",
    "Epoch: 2 \n",
    "\n",
    "{'generated_text': 'في في في'}\n",
    "--------------------------------------\n",
    "======================================\n",
    "--------------------------------------\n",
    "Train Loss: 4.4462\n",
    "Validation Loss: 2.1080\n",
    "Epoch: 0\n",
    "\n",
    "[{'generated_text': 'فرا أحمد القرآن'}]\n",
    "[{'generated_text': 'لبس الحقيقي بكل جديد'}]\n",
    "[{'generated_text': 'لدينا عبر نرسل معلومات الحجر عبر البريد الإلكتروني'}]\n",
    "--------------------------------------\n",
    "======================================\n",
    "--------------------------------------\n",
    "Train Loss: 2.0097\n",
    "Validation Loss: 1.2814\n",
    "Epoch: 1\n",
    "\n",
    "[{'generated_text': 'قرأ أحمد القرآن'}]\n",
    "[{'generated_text': 'لتس اشت بكل جديد'}]\n",
    "[{'generated_text': 'لدينا عبر نرسل معلومات الحجر عبر البريد الإلكتروني'}]\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
