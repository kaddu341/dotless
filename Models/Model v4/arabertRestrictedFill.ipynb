{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from datasets import *\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import pipeline\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForMaskedLM\n",
    "import torch\n",
    "from transformers import TFAutoModelForMaskedLM\n",
    "import line_profiler\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"/Users/ammar/Developer/git-repos/dotless/Models/Model v3/AR-multi-dotted-Small-arrow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 14, 28, 41, 57, 66, 92, 102, 118, 119, 122, 123, 126, 130, 133, 134, 152, 164, 174, 178, 179, 188, 189, 210, 216, 223, 237, 258, 263, 269, 270, 272, 278, 306, 320, 323, 330, 340, 348, 352, 356, 363, 396, 404, 428, 438, 443, 444, 451, 466, 473, 490, 497, 498, 502, 505, 510, 514, 520, 523, 529, 531, 537, 538, 540, 541, 554, 566, 569, 575, 587, 588, 598, 601, 607, 609, 613, 625, 626, 632, 640, 662, 664, 674, 677, 679, 688, 690, 692, 702, 709, 722, 723, 727, 728, 745, 755, 761, 767, 774, 782, 796, 798, 799, 804, 805, 818, 831, 832, 836, 846, 851, 853, 868, 878, 894, 895, 902, 923, 931, 944, 956, 965, 968, 993, 1001, 1012, 1015, 1033, 1043, 1049, 1057, 1060, 1062, 1070, 1082, 1095, 1103, 1109, 1115, 1117, 1118, 1125, 1126, 1142, 1151, 1155, 1159, 1165, 1169, 1177, 1196, 1197, 1200, 1204, 1205, 1210, 1212, 1216, 1234, 1241, 1245, 1251, 1253, 1260, 1275, 1286, 1290, 1302, 1310, 1316, 1328, 1330, 1331, 1332, 1337, 1338, 1341, 1343, 1351, 1362, 1364, 1368, 1377, 1387, 1394, 1398, 1403, 1425, 1427, 1428, 1431, 1432, 1442, 1454, 1456, 1477, 1489, 1494, 1496, 1508, 1514, 1516, 1519, 1521, 1522, 1523, 1524, 1526, 1538, 1543, 1558, 1563, 1564, 1573, 1591, 1592, 1596, 1606, 1612, 1614, 1642, 1643, 1649, 1656, 1658, 1661, 1681, 1687, 1689, 1699, 1702, 1704, 1714, 1718, 1726, 1732, 1737, 1745, 1757, 1759, 1762, 1763, 1764, 1786, 1789, 1810, 1813, 1818, 1828, 1831, 1839, 1848, 1851, 1871, 1878, 1884, 1916, 1919, 1923, 1924, 1943, 1949, 1952, 1954, 1993, 1994, 1997, 2004, 2006, 2017, 2030, 2038, 2039, 2040, 2047, 2051, 2071, 2073, 2079, 2106, 2108, 2121, 2133, 2142, 2173, 2174, 2180, 2181, 2199, 2205, 2206, 2208, 2213, 2220, 2223, 2225, 2228, 2240, 2248, 2266, 2269, 2270, 2274, 2283, 2289, 2307, 2325, 2334, 2349, 2366, 2375, 2376, 2381, 2384, 2388, 2395, 2398, 2404, 2406, 2411, 2420, 2424, 2425, 2432, 2433, 2439, 2442, 2452, 2468, 2469, 2483, 2505, 2529, 2531, 2547, 2566, 2578, 2580, 2590, 2591, 2593, 2597, 2598, 2610, 2616, 2623, 2626, 2636, 2637, 2639, 2648, 2673, 2676, 2701, 2704, 2707, 2709, 2717, 2719, 2746, 2760, 2762, 2764, 2769, 2780, 2787, 2802, 2803, 2819, 2820, 2823, 2825, 2830, 2847, 2859, 2860, 2861, 2863, 2883, 2889, 2900, 2905, 2925, 2930, 2939, 2946, 2956, 2964, 2972, 2979, 2980, 2991, 2996, 3014, 3020, 3029, 3034, 3045, 3048, 3056, 3067, 3068, 3072, 3074, 3075, 3086, 3095, 3101, 3117, 3149, 3158, 3182, 3186, 3200, 3201, 3208, 3217, 3236, 3238, 3256, 3266, 3267, 3291, 3294, 3302, 3305, 3312, 3318, 3320, 3322, 3330, 3335, 3343, 3357, 3359, 3366, 3367, 3395, 3398, 3409, 3414, 3422, 3436, 3440, 3450, 3465, 3468, 3479, 3485, 3491, 3497, 3504, 3508, 3513, 3522, 3527, 3539, 3552, 3553, 3554, 3556, 3560, 3561, 3583, 3584, 3598, 3609, 3610, 3617, 3626, 3656, 3668, 3671, 3680, 3695, 3700, 3701, 3712, 3713, 3718, 3742, 3756, 3759, 3769, 3775, 3805, 3807, 3809, 3822, 3834, 3841, 3849, 3854, 3857, 3858, 3860, 3870, 3881, 3889, 3914, 3920, 3921, 3933, 3936, 3945, 3946, 3948, 3950, 3951, 3953, 3956, 3959, 3980, 3992, 4002, 4016, 4029, 4032, 4037, 4052, 4053, 4055, 4078, 4099, 4105, 4119, 4122, 4129, 4137, 4138, 4139, 4142, 4154, 4157, 4163, 4171, 4176, 4198, 4209, 4215, 4217, 4232, 4235, 4247, 4251, 4263, 4267, 4270, 4284, 4287, 4290, 4295, 4318, 4328, 4330, 4332, 4341, 4342, 4363, 4364, 4407, 4417, 4418, 4422, 4431, 4440, 4442, 4460, 4469, 4472, 4475, 4476, 4478, 4479, 4480, 4492, 4495, 4514, 4516, 4519, 4522, 4530, 4542, 4553, 4556, 4559, 4566, 4571, 4572, 4573, 4577, 4578, 4579, 4580, 4583, 4593, 4595, 4608, 4612, 4617, 4627, 4642, 4644, 4650, 4653, 4667, 4680, 4704, 4715, 4720, 4723, 4741, 4744, 4745, 4768, 4797, 4815, 4827, 4841, 4856, 4860, 4877, 4887, 4898, 4902, 4912, 4918, 4930, 4960, 4975, 4979, 4982, 4986, 4990, 4991, 5001, 5005, 5007, 5017, 5030, 5035, 5044, 5055, 5072, 5078, 5080, 5092, 5097, 5099, 5103, 5106, 5112, 5129, 5140, 5142, 5144, 5147, 5156, 5161, 5177, 5180, 5184, 5198, 5204, 5212, 5241, 5250, 5255, 5259, 5273, 5278, 5287, 5299, 5305, 5306, 5307, 5309, 5315, 5332, 5342, 5346, 5351, 5363, 5375, 5376, 5388, 5410, 5421, 5423, 5427, 5434, 5449, 5462, 5477, 5479, 5480, 5483, 5485, 5504, 5508, 5510, 5514, 5524, 5525, 5528, 5543, 5556, 5564, 5571, 5572, 5573, 5574, 5576, 5584, 5599, 5602, 5604, 5632, 5633, 5643, 5650, 5652, 5653, 5659, 5669, 5682, 5689, 5692, 5700, 5701, 5715, 5719, 5720, 5750, 5766, 5774, 5783, 5790, 5801, 5810, 5812, 5834, 5840, 5843, 5845, 5848, 5874, 5879, 5881, 5882, 5886, 5905, 5906, 5908, 5909, 5913, 5917, 5926, 5927, 5937, 5947, 5956, 5957, 5958, 5959, 5963, 5971, 5974, 5978, 5980, 5981, 5984, 5992, 6006, 6009, 6010, 6012, 6019, 6063, 6069, 6073, 6091, 6092, 6094, 6102, 6105, 6116, 6121, 6126, 6133, 6146, 6157, 6159, 6163, 6173, 6176, 6185, 6195, 6197, 6209, 6213, 6228, 6231, 6233, 6243, 6244, 6270, 6271, 6272, 6284, 6291, 6293, 6306, 6311, 6317, 6329, 6336, 6339, 6343, 6344, 6347, 6357, 6365, 6382, 6392, 6393, 6396, 6408, 6409, 6413, 6423, 6426, 6438, 6444, 6450, 6453, 6464, 6475, 6499, 6505, 6509, 6516, 6538, 6549, 6551, 6556, 6564, 6569, 6571, 6591, 6597, 6612, 6640, 6648, 6652, 6654, 6662, 6665, 6686, 6692, 6713, 6717, 6743, 6745, 6769, 6775, 6777, 6783, 6787, 6789, 6790, 6795, 6799, 6806, 6815, 6822, 6834, 6835, 6836, 6841, 6842, 6846, 6847, 6850, 6869, 6870, 6875, 6893, 6902, 6914, 6932, 6936, 6939, 6940, 6949, 6954, 6982, 6986, 6987, 7017, 7025, 7037, 7044, 7049, 7052, 7057, 7065, 7071, 7076, 7086, 7102, 7107, 7110, 7114, 7123, 7135, 7142, 7145, 7148, 7154, 7156, 7173, 7186, 7194, 7195, 7215, 7218, 7230, 7239, 7248, 7269, 7270, 7304, 7306, 7314, 7329, 7335, 7339, 7350, 7353, 7368, 7379, 7397, 7406, 7407, 7409, 7416, 7425, 7428, 7433, 7436, 7456, 7476, 7477, 7485, 7498, 7520, 7525, 7527, 7539, 7560, 7563, 7570, 7572, 7589, 7592, 7609, 7637, 7641, 7650, 7656, 7662, 7668, 7691, 7693, 7702, 7709, 7730, 7733, 7736, 7749, 7764, 7773, 7786, 7788, 7789, 7792, 7796, 7798, 7800, 7804, 7812, 7816, 7817, 7818, 7832, 7839, 7840, 7843, 7847, 7862, 7865, 7905, 7906, 7910, 7911, 7946, 7954, 7963, 7974, 7981, 7983, 7989, 7996, 8001, 8004, 8005, 8018, 8024, 8030, 8032, 8033, 8035, 8036, 8040, 8041, 8054, 8055, 8066, 8068, 8069, 8071, 8074, 8083, 8087, 8089, 8093, 8094, 8107, 8110, 8113, 8133, 8136, 8147, 8155, 8157, 8160, 8162, 8179, 8209, 8213, 8214, 8224, 8230, 8237, 8247, 8262, 8264, 8269, 8272, 8273, 8281, 8283, 8300, 8302, 8322, 8342, 8343, 8346, 8349, 8364, 8366, 8370, 8376, 8379, 8385, 8389, 8391, 8395, 8438, 8444, 8448, 8454, 8460, 8461, 8462, 8468, 8472, 8485, 8509, 8518, 8545, 8555, 8556, 8560, 8571, 8579, 8587, 8590, 8595, 8596, 8599, 8601, 8605, 8619, 8621, 8627, 8628, 8633, 8636, 8644, 8646, 8657, 8666, 8679, 8687, 8690, 8694, 8696, 8713, 8717, 8724, 8735, 8740, 8744, 8754, 8762, 8767, 8768, 8770, 8774, 8779, 8781, 8822, 8830, 8831, 8844, 8847, 8854, 8861, 8862, 8864, 8868, 8872, 8889, 8929, 8933, 8937, 8938, 8946, 8954, 8956, 8961, 8966, 8990, 8991, 8993, 8996, 9001, 9002, 9006, 9017, 9024, 9030, 9033, 9034, 9038, 9043, 9046, 9048, 9051, 9070, 9074, 9077, 9078, 9092, 9102, 9105, 9115, 9116, 9119, 9127, 9137, 9138, 9140, 9157, 9160, 9165, 9173, 9182, 9183, 9194, 9214, 9217, 9219, 9228, 9237, 9260, 9267, 9269, 9273, 9275, 9276, 9287, 9309, 9313, 9314, 9323, 9325, 9328, 9348, 9361, 9362, 9374, 9379, 9395, 9397, 9399, 9414, 9423, 9425, 9440, 9441, 9446, 9469, 9473, 9474, 9476, 9488, 9491, 9501, 9510, 9520, 9529, 9544, 9548, 9559, 9563, 9565, 9572, 9578, 9582, 9586, 9590, 9592, 9594, 9596, 9604, 9608, 9610, 9615, 9637, 9639, 9644, 9654, 9656, 9661, 9676, 9683, 9685, 9688, 9695, 9708, 9709, 9710, 9732, 9734, 9746, 9749, 9760, 9772, 9773, 9785, 9808, 9809, 9818, 9820, 9824, 9839, 9841, 9842, 9843, 9848, 9855, 9867, 9871, 9877, 9886, 9891, 9895, 9902, 9903, 9905, 9907, 9917, 9927, 9949, 9950, 9959, 9960, 9968, 9991, 9993, 9996, 9997]\n",
      "1306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Masked': 'السؤال كيف توفق بين دخلك والمنصرفات [MASK] الله كريم فخلص إلى أن',\n",
       " 'Options': ['ؤةي',\n",
       "  'ؤةى',\n",
       "  'ؤةئ',\n",
       "  'ؤهي',\n",
       "  'ؤهى',\n",
       "  'ؤهئ',\n",
       "  'وةي',\n",
       "  'وةى',\n",
       "  'وةئ',\n",
       "  'وهي',\n",
       "  'وهى',\n",
       "  'وهئ'],\n",
       " 'Target': 'وهي'}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicies = []\n",
    "for i in range(10000):\n",
    "    length = len(dataset['train'][i][\"Options\"])\n",
    "    if length > 10 and length <= 20:\n",
    "        indicies.append(i)\n",
    "\n",
    "print(indicies)\n",
    "print(len(indicies))\n",
    "dataset['train'][indicies[3]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Masked': 'السؤال كيف توفق بين دخلك والمنصرفات [MASK] الله كريم فخلص إلى أن',\n",
       " 'Options': ['ؤةي',\n",
       "  'ؤةى',\n",
       "  'ؤةئ',\n",
       "  'ؤهي',\n",
       "  'ؤهى',\n",
       "  'ؤهئ',\n",
       "  'وةي',\n",
       "  'وةى',\n",
       "  'وةئ',\n",
       "  'وهي',\n",
       "  'وهى',\n",
       "  'وهئ'],\n",
       " 'Target': 'وهي'}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset['train'][indicies[3]]\n",
    "input_text = example[\"Masked\"]\n",
    "candidates = example[\"Options\"]\n",
    "example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.framework\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['السؤال',\n",
       " 'كيف',\n",
       " 'توف',\n",
       " '##ق',\n",
       " 'بين',\n",
       " 'دخل',\n",
       " '##ك',\n",
       " 'والمن',\n",
       " '##صرف',\n",
       " '##ات',\n",
       " '[MASK]',\n",
       " 'الله',\n",
       " 'كريم',\n",
       " 'فخ',\n",
       " '##لص',\n",
       " 'إلى',\n",
       " 'أن']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = tokenizer.tokenize(input_text)\n",
    "mask_token_index = tokenized_text.index(\"[MASK]\")\n",
    "\n",
    "print(mask_token_index)\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from torch.nn.functional import softmax\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 005bcc89-faaf-45aa-b7b3-9fefd802b8ff)')' thrown while requesting HEAD https://huggingface.co/CAMeL-Lab/bert-base-arabic-camelbert-mix/resolve/main/tokenizer_config.json\n",
      "Some weights of the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-mix were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"CAMeL-Lab/bert-base-arabic-camelbert-mix\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"CAMeL-Lab/bert-base-arabic-camelbert-mix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dataset['train'][indicies[11]]\n",
    "input_text = example[\"Masked\"]\n",
    "candidates = example[\"Options\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'كانون الاولديسمبر [MASK] ظريف حملة تودد تجاه جيران ايران العرب في اطار'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_word_probabilities(input_text, candidate_words):\n",
    "    tokenized_text = tokenizer.tokenize(input_text)\n",
    "\n",
    "    masked_word_index = tokenized_text.index('[MASK]')\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "    input_ids = torch.tensor(input_ids).unsqueeze(0)  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)\n",
    "\n",
    "    predictions = output.logits[0, masked_word_index].softmax(dim=0)\n",
    "\n",
    "    candidate_probabilities = {}\n",
    "    for candidate_word in candidate_words:\n",
    "        candidate_word_id = tokenizer.convert_tokens_to_ids(candidate_word)\n",
    "        candidate_probabilities[candidate_word] = predictions[candidate_word_id].item()\n",
    "\n",
    "    return candidate_probabilities\n",
    "\n",
    "\n",
    "def generate_probabilties_end(example_num):\n",
    "    example = dataset['train'][indicies[example_num]]\n",
    "    input_text = example[\"Masked\"]\n",
    "    candidates = example[\"Options\"]\n",
    "\n",
    "    word_probabilities = get_candidate_word_probabilities(input_text, candidates)\n",
    "\n",
    "    sorted_words = sorted(word_probabilities, key=word_probabilities.get, reverse=True)\n",
    "    most_probable_word = sorted_words[0]\n",
    "\n",
    "    return example, word_probabilities, sorted_words, most_probable_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 'النطق', Probability: 0.9995705485\n",
      "Word: 'آلنظف', Probability: 0.0000000001\n",
      "Word: 'آلنظق', Probability: 0.0000000001\n",
      "Word: 'آلنطف', Probability: 0.0000000001\n",
      "Word: 'آلنطق', Probability: 0.0000000001\n",
      "Word: 'إلنظف', Probability: 0.0000000001\n",
      "Word: 'إلنظق', Probability: 0.0000000001\n",
      "Word: 'إلنطف', Probability: 0.0000000001\n",
      "Word: 'إلنطق', Probability: 0.0000000001\n",
      "Word: 'ألنظف', Probability: 0.0000000001\n",
      "Word: 'ألنظق', Probability: 0.0000000001\n",
      "Word: 'ألنطف', Probability: 0.0000000001\n",
      "Word: 'ألنطق', Probability: 0.0000000001\n",
      "Word: 'النظف', Probability: 0.0000000001\n",
      "Word: 'النظق', Probability: 0.0000000001\n",
      "Word: 'النطف', Probability: 0.0000000001\n",
      "\n",
      "Most probable word: النطق\n",
      "Target word: النطق\n",
      "------------------------------------------\n",
      "Sucess at probability level: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Masked': 'قرارها بمد أجل [MASK] بالحكم لحين الانتها من قراة ملف القضية وإيداع',\n",
       " 'Options': ['آلنظف',\n",
       "  'آلنظق',\n",
       "  'آلنطف',\n",
       "  'آلنطق',\n",
       "  'إلنظف',\n",
       "  'إلنظق',\n",
       "  'إلنطف',\n",
       "  'إلنطق',\n",
       "  'ألنظف',\n",
       "  'ألنظق',\n",
       "  'ألنطف',\n",
       "  'ألنطق',\n",
       "  'النظف',\n",
       "  'النظق',\n",
       "  'النطف',\n",
       "  'النطق'],\n",
       " 'Target': 'النطق'}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_eg = 2\n",
    "example, word_probabilities, sorted_words, most_probable_word = generate_probabilties_end(num_eg)\n",
    "for word in sorted_words:\n",
    "    probability = word_probabilities[word]\n",
    "    print(f\"Word: '{word}', Probability: {probability:.10f}\")\n",
    "    \n",
    "print()\n",
    "\n",
    "print(\"Most probable word:\", most_probable_word)\n",
    "print(\"Target word:\", example[\"Target\"])\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "for i in range(len(sorted_words)):\n",
    "    if sorted_words[i] == example[\"Target\"]:\n",
    "        print(\"Sucess at probability level:\", i)\n",
    "        break\n",
    "sucess_level = i\n",
    "\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64,  4,  0,  0,  1,  1,  0,  3,  3,  2,  4,  4,  3,  0,  2,  6,  2,\n",
       "        1,  0,  0])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = np.zeros(20, dtype =int)\n",
    "for i in range(100):\n",
    "    num_eg = i\n",
    "    example, word_probabilities, sorted_words, most_probable_word = generate_probabilties_end(num_eg)\n",
    "    for word in sorted_words:\n",
    "        probability = word_probabilities[word]\n",
    "\n",
    "    for i in range(len(sorted_words)):\n",
    "        if sorted_words[i] == example[\"Target\"]:\n",
    "            count[i] += 1\n",
    "            break\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
