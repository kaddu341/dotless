{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert model to TFLite\n",
    "- Credit: @awwab-ahmad\n",
    "- Model: https://huggingface.co/awwab-ahmed/bert-base-arabic-camelbert-mix-finetuned-AR-dotted-mediumPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow transformers\n",
    "# %pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize tokenizer and model\n",
    "checkpoint = \"awwab-ahmed/bert-base-arabic-camelbert-mix-finetuned-AR-dotted-mediumPlus\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = TFAutoModelForMaskedLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"tf-model\")\n",
    "tokenizer.save_pretrained(\"tf-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # dynamic range quantization to reduce size\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"quant_model.tflite\", \"wb\") as file:\n",
    "  file.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_text as tf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocabulary\n",
    "with open(\"tf-model/vocab.txt\", \"r\") as file:\n",
    "    vocab = [line.rstrip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([10864 28995  1012  9111  1013  2104  3772 10675], shape=(8,), dtype=int32)\n",
      "{'input_ids': [2, 10864, 28995, 1012, 9111, 1013, 2104, 3772, 10675, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "tf.Tensor([10864 28995  1012  9111  1013  2104  3772 10675], shape=(8,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "test_str = \"طالما أشكو غرامي يا نور الوجود\"\n",
    "tokenized_text = tokenizer.tokenize(test_str)\n",
    "tokens = tokenizer(test_str)\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "input_ids = tf.constant(input_ids, dtype=tf.int32)\n",
    "print(input_ids)\n",
    "print(tokens)\n",
    "input_ids = tf.constant(input_ids, dtype=tf.int32)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "أف\n",
      "['أف', '##إ', '##ست', '##س', '##قين', '##اكم', '##وهم', '##ا']\n"
     ]
    }
   ],
   "source": [
    "def encode_word(word):\n",
    "    tokens = []\n",
    "    while len(word) > 0:\n",
    "        i = len(word)\n",
    "        while i > 0 and word[:i] not in vocab:\n",
    "            i -= 1\n",
    "        if i == 0:\n",
    "            return [\"[UNK]\"]\n",
    "        tokens.append(word[:i])\n",
    "        word = word[i:]\n",
    "        if len(word) > 0:\n",
    "            word = f\"##{word}\"\n",
    "    return tokens\n",
    "\n",
    "print(encode_word(\"أفإستسقيناكموهما\"))\n",
    "print(tokenizer.tokenize(\"أفإستسقيناكموهما\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFMaskedLMOutput(loss=None, logits=<tf.Tensor: shape=(1, 3, 30000), dtype=float32, numpy=\n",
      "array([[[-3.145209  , -0.57819   , -1.1382166 , ..., -2.4511776 ,\n",
      "         -3.7814074 , -2.852653  ],\n",
      "        [-5.1905065 , -3.964841  , -0.97261924, ..., -3.3409166 ,\n",
      "         -6.081559  , -5.9540405 ],\n",
      "        [-6.482839  , -3.3633132 , -1.3157046 , ..., -5.052669  ,\n",
      "         -5.12359   , -7.425818  ]]], dtype=float32)>, hidden_states=None, attentions=None)\n",
      "(30000,)\n"
     ]
    }
   ],
   "source": [
    "test_str = \"البيت الكبير [MASK]\"\n",
    "tokenized_text = tokenizer.tokenize(test_str)\n",
    "masked_word_index = tokenized_text.index('[MASK]')\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "input_ids = tf.constant([input_ids], dtype=tf.int32)\n",
    "output = model(input_ids)\n",
    "print(output)\n",
    "predictions = tf.nn.softmax(output.logits[0, masked_word_index])\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1.8296893e-06 2.3835250e-05 1.3614548e-05 ... 3.6626166e-06\n",
      "   9.6845622e-07 2.4515068e-06]\n",
      "  [1.5803280e-08 5.3832835e-08 1.0728837e-06 ... 1.0046484e-07\n",
      "   6.4828827e-09 7.3646009e-09]\n",
      "  [6.3258192e-08 1.4318900e-06 1.1096222e-05 ... 2.6438192e-07\n",
      "   2.4628113e-07 2.4636934e-08]]], shape=(1, 3, 30000), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "predictions = tf.math.softmax(output.logits, axis=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'LABEL_0', 1: 'LABEL_1'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at awwab-ahmed/bert-base-arabic-camelbert-mix-finetuned-AR-dotted-mediumPlus.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.05004889890551567,\n",
       "  'token': 2854,\n",
       "  'token_str': 'العمل',\n",
       "  'sequence': 'الهدف من الحياة هو العمل.'},\n",
       " {'score': 0.04471169784665108,\n",
       "  'token': 3696,\n",
       "  'token_str': 'الحياة',\n",
       "  'sequence': 'الهدف من الحياة هو الحياة.'},\n",
       " {'score': 0.022871755063533783,\n",
       "  'token': 7908,\n",
       "  'token_str': 'التفكير',\n",
       "  'sequence': 'الهدف من الحياة هو التفكير.'},\n",
       " {'score': 0.01748461276292801,\n",
       "  'token': 7676,\n",
       "  'token_str': 'العودة',\n",
       "  'sequence': 'الهدف من الحياة هو العودة.'},\n",
       " {'score': 0.016479946672916412,\n",
       "  'token': 1979,\n",
       "  'token_str': 'أن',\n",
       "  'sequence': 'الهدف من الحياة هو أن.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='awwab-ahmed/bert-base-arabic-camelbert-mix-finetuned-AR-dotted-mediumPlus')\n",
    "unmasker(\"الهدف من الحياة هو [MASK] .\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
